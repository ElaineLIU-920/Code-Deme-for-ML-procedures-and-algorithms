{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hypothesis Test Demo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some Package Import and Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance of model 1: [0.417, 0.7203, 0.0001, 0.3023, 0.1468, 0.0923, 0.1863, 0.3456, 0.3968, 0.5388]\n",
      "Performance of model 2: [0.836, 0.4259, 0.9497, 0.8353, 0.8204, 0.7303, 0.6046, 1.0193, 0.6997, 0.6668]\n",
      "Performance of model 3:  [0.5808, 0.7381, 0.3209, 0.5408, 0.9229, 0.9263, 0.1556, 0.2372, 0.0815, 0.4708]\n"
     ]
    }
   ],
   "source": [
    "from numpy import *\n",
    "from scipy import stats\n",
    "\n",
    "# data 1 is the performance score of 10-fold cv of model 1\n",
    "random.seed(1)\n",
    "data1 = [float('{:.4f}'.format(i)) for i in random.rand(10)]\n",
    "# data 2 is the performance score of 10-fold cv of model 2\n",
    "random.seed(2)\n",
    "data2 = [float('{:.4f}'.format(i)) for i in random.rand(10)+0.4]\n",
    "# data 3 is the performance score of 10-fold cv of model 3\n",
    "random.seed(3)\n",
    "data3 = [float('{:.4f}'.format(i)) for i in random.rand(10)+0.03]\n",
    "\n",
    "# Print the data\n",
    "print('Performance of model 1:',data1)\n",
    "print('Performance of model 2:',data2)\n",
    "print('Performance of model 3: ',data3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mean and Confidence interval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model has a mean of 0.314630 with a 95% confidence interval: [0.0003, 0.0003]\n"
     ]
    }
   ],
   "source": [
    "# Set significance level\n",
    "alpha = 0.05\n",
    "\n",
    "# Mean of model 1\n",
    "mean1 = mean(data1)\n",
    "\n",
    "# Confidence interval of model 1\n",
    "lower = percentile(data1, alpha/2)\n",
    "upper = percentile(data1, alpha/2)\n",
    "print('The model has a mean of %f with a %d%% confidence interval: [%.4f, %.4f]' % (mean1,(1-alpha)*100,lower, upper))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Student's t-Test for One-Sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t statistic value is 0.0000.\n",
      "P-value is 1.0000.\n",
      "Probably the average performance of model 1 is 0.3146 at a 95% confidence level.\n"
     ]
    }
   ],
   "source": [
    "# Calculate the T-test for the mean of ONE group of scores. Let' have model 1 for example.\n",
    "\n",
    "# Set significance level\n",
    "alpha = 0.05\n",
    "\n",
    "# Test if mean of model 1 is equal to mean1.\n",
    "t,p = stats.ttest_1samp(data1, mean1)\n",
    "print('t statistic value is %.4f.\\nP-value is %.4f.'%(t,p))\n",
    "\n",
    "# Conclude\n",
    "if p > alpha:\n",
    "    print('Probably the average performance of model 1 is %.4f at a %d%% confidence level.' %(mean1,(1-alpha)*100))\n",
    "else:\n",
    "    print('Probably the average performance of model 1 is not %.4f at a %d%% confidence level.' %(mean1,(1-alpha)*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Paired Student's t-Test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Approach 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t statistic value is -4.0680.\n",
      "P-value is 0.0028.\n",
      "Probably different distributions at 95% confidence level.\n"
     ]
    }
   ],
   "source": [
    "# Set significance level\n",
    "alpha = 0.05\n",
    "\n",
    "# Calculate the difference of model 1 and model 2\n",
    "diff_clf = [a-b for a,b in zip(data1,data2)]\n",
    "\n",
    "# Test if the mean of difference is equal to 0.\n",
    "t,p = stats.ttest_1samp(diff_clf, 0.0)\n",
    "print('t statistic value is %.4f.\\nP-value is %.4f.'%(t,p))\n",
    "\n",
    "# Conclude\n",
    "if p > 0.05:\n",
    "    print('Probably the same distribution at a %d%% confidence level.' %((1-alpha)*100))\n",
    "else:\n",
    "    print('Probably different distributions at %d%% confidence level.' %((1-alpha)*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Approach 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t statistic value is -4.0680.\n",
      "P-value is 0.0028.\n",
      "Probably different distributions at a 95% confidence level.\n"
     ]
    }
   ],
   "source": [
    "# This is a two-sided test for the null hypothesis that 2 related samples have identical average values. Let's have model 1 and 2 for example\n",
    "\n",
    "# Set significance level\n",
    "alpha = 0.05\n",
    "\n",
    "# Test if the distributions are the same.\n",
    "t,p = stats.ttest_rel(data1,data2)\n",
    "print('t statistic value is %.4f.\\nP-value is %.4f.'%(t,p))\n",
    "\n",
    "# Conclude\n",
    "if p > alpha:\n",
    "    print('Probably the same distribution at a %d%% confidence level.' %((1-alpha)*100))\n",
    "else:\n",
    "    print('Probably different distributions at a %d%% confidence level.' %((1-alpha)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t statistic value is -1.5411.\n",
      "P-value is 0.1577.\n",
      "Probably the same distribution at a 95% confidence level.\n"
     ]
    }
   ],
   "source": [
    "# Set significance level\n",
    "alpha = 0.05\n",
    "\n",
    "# Another example for model 1 and 3.\n",
    "t,p = stats.ttest_rel(data1,data3)\n",
    "print('t statistic value is %.4f.\\nP-value is %.4f.'%(t,p))\n",
    "\n",
    "# Conclude\n",
    "if p > alpha:\n",
    "    print('Probably the same distribution at a %d%% confidence level.' %((1-alpha)*100))\n",
    "else:\n",
    "    print('Probably different distributions at a %d%% confidence level.' %((1-alpha)*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wilcoxon Signed-rankTest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t statistic value is 2.0000.\n",
      "P-value is 0.0093.\n",
      "Probably different distributions at a 95% confidence level.\n"
     ]
    }
   ],
   "source": [
    "# The Wilcoxon signed-rank test tests the null hypothesis that two related paired samples come from the same distribution. In particular, it tests whether the distribution of the differences x - y is symmetric about zero. It is a non-parametric version of the paired T-test.\n",
    "\n",
    "# Set significance level\n",
    "alpha = 0.05\n",
    "\n",
    "# Test if the distributions are the same.\n",
    "t,p = stats.wilcoxon(data1,data2)\n",
    "print('t statistic value is %.4f.\\nP-value is %.4f.'%(t,p))\n",
    "\n",
    "# Conclude\n",
    "if p > alpha:\n",
    "    print('Probably the same distribution at a %d%% confidence level.' %((1-alpha)*100))\n",
    "else:\n",
    "    print('Probably different distributions at a %d%% confidence level.' %((1-alpha)*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## McNemarâ€™s Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "statistic=1.000, p-value=0.003.\n",
      "Different proportions of errors (reject H0) at a 95% confidence level.\n"
     ]
    }
   ],
   "source": [
    "# Example of implementing the mcnemar test\n",
    "\n",
    "from statsmodels.stats.contingency_tables import mcnemar\n",
    "\n",
    "# Set significance level\n",
    "alpha = 0.05\n",
    "\n",
    "# Define contingency table\n",
    "table = [[100, 12],\n",
    "         [1, 30]]\n",
    "\n",
    "# Implement mcnemar test\n",
    "result = mcnemar(table, exact=True)\n",
    "print('statistic=%.3f, p-value=%.3f.' % (result.statistic, result.pvalue))\n",
    "\n",
    "# Conclude\n",
    "if p > alpha:\n",
    "\tprint('Same proportions of errors (fail to reject H0) at a %d%% confidence level.' %((1-alpha)*100))\n",
    "else:\n",
    "\tprint('Different proportions of errors (reject H0) at a %d%% confidence level.' %((1-alpha)*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Friedman Test and Nemenyi Test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Friedman test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t statistic value is 6.2000\n",
      "P-value is 0.0450\n",
      "Probably different distributions at a 95% confidence level.\n"
     ]
    }
   ],
   "source": [
    "# The Friedman test tests the null hypothesis that the samples have the same distribution. \n",
    "\n",
    "# Set significance level\n",
    "alpha = 0.05\n",
    "\n",
    "# Test if the distributions are the same.\n",
    "t,p = stats.friedmanchisquare(data1,data2,data3)\n",
    "print('t statistic value is %.4f\\nP-value is %.4f'%(t,p))\n",
    "\n",
    "# Conclude\n",
    "if p > alpha:\n",
    "    print('Probably the same distribution at a %d%% confidence level.' %((1-alpha)*100))\n",
    "else:\n",
    "    print('Probably different distributions at a %d%% confidence level.' %((1-alpha)*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The post-hoc test: Nemenyi test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Critical value of q_alpha is:  [2.34370059]\n",
      "Critical difference(CD) is:  [1.04813477]\n",
      "The average rank of each model is: [1.5, 2.6, 1.9]\n",
      "The difference table is:\n",
      " [[0.  1.1 0.4]\n",
      " [1.1 0.  0.7]\n",
      " [0.4 0.7 0. ]]\n",
      "The performance of model 1 and 2 is different at 0.05 significance level.\n",
      "\n",
      "The performance of model 1 and 3 is the same at 0.05 significance level.\n",
      "\n",
      "The performance of model 2 and 3 is the same at 0.05 significance level.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# The post-hoc test is deploed after we reject the null hypothesis of Friedman test. Here, we adopt Nemenyi test as an example.\n",
    "\n",
    "# Set significance level\n",
    "alpha = 0.05\n",
    "# Set the number of models to be compared\n",
    "k =3\n",
    "\n",
    "# Obtain the value of q_alpha from \n",
    "import rpy2.robjects as robjects\n",
    "r = robjects.r\n",
    "q_alpha = r['qtukey'](1-alpha,k,float('inf'))/sqrt(2)  #qtukey(0.95,3,Inf)/sqrt(2) in R language\n",
    "print('Critical value of q_alpha is: ',q_alpha)\n",
    "\n",
    "# Calculate critical difference\n",
    "CD = q_alpha*sqrt(k*(k+1)/(6*N))\n",
    "print('Critical difference(CD) is: ',CD)\n",
    "\n",
    "# Rank data\n",
    "data = vstack((data1,data2,data3)).T\n",
    "data = data.astype(float)\n",
    "for i in range(len(data)):\n",
    "    data[i] = stats.rankdata(data[i])\n",
    "# print(data)\n",
    "                  \n",
    "# Compute the average rank and the difference between the average of the rank\n",
    "avgrank = []\n",
    "for i in range(len(data[0])):\n",
    "   avgrank.append(mean(data[:,i]))\n",
    "print('The average rank of each model is:', avgrank)\n",
    "diff = []\n",
    "for i in range(k):\n",
    "    if i == 0:\n",
    "        diff = abs(avgrank - avgrank[i])\n",
    "    else: \n",
    "        diff = vstack((diff,abs(avgrank - avgrank[i])))\n",
    "print('The difference table is:\\n',diff)\n",
    "\n",
    "# Conclude\n",
    "for i in range(k):\n",
    "    for j in range(i+1,k):\n",
    "        if diff[i,j] > CD:\n",
    "            print('The performance of model %d and %d is different at %.2f significance level.\\n' %(i+1,j+1,alpha))\n",
    "        else:\n",
    "            print('The performance of model %d and %d is the same at %.2f significance level.\\n' %(i+1,j+1,alpha))   "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
