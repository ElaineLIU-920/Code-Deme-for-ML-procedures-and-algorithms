{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Selection Demo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model evaluation and model selection are two different concepts, representing two different stages:\n",
    "- Model selection: Select the best model from a certain model space according to a set of model representations of different complexity;\n",
    "- Model evaluation: After selecting a (best) model, evaluate its performance such as prediction error against new data.\n",
    "\n",
    "We adopt the dataset from Genome-wide cell-free DNA fragmentation in patients with cancer as the example."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some Package Import and Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of samples and features are 423 and 45, respectively\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "\n",
    "\n",
    "# from numpy import *\n",
    "from sklearn import *\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "xl = pd.ExcelFile('data2.xlsx')\n",
    "xl.sheet_names # we'll take 7th\n",
    "dfs = {sheet: xl.parse(sheet) for sheet in xl.sheet_names}\n",
    "data1 = dfs['7']\n",
    "data2 = dfs['1'].loc[:,['Patient','Age at Diagnosis']].drop([554]).drop_duplicates()\n",
    "data3 = pd.read_csv('data1.csv')\n",
    "combined_data = data1.set_index('Patient').join(data2.set_index('Patient')).join(data3.set_index('Patient'))\n",
    "combined_data['label'] = (combined_data['Patient Type'] == 'Healthy').astype(int)\n",
    "combined_data = combined_data.drop(['Patient Type'],axis=1)\n",
    "print('The number of samples and features are %d and %d, respectively'%(combined_data.shape[0],combined_data.shape[1]))\n",
    "\n",
    "x = combined_data.iloc[:, 0:44]\n",
    "x[isnan(x)] = 0\n",
    "y=combined_data.iloc[:,44]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resample Methods: Nested k-fold cross validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Select different type of models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier with higest accuracy on validation set is RandomForest.\n",
      "Classifier with higest accuracy on validation set is RandomForest.\n",
      "Classifier with higest accuracy on validation set is SVM.\n",
      "Classifier with higest accuracy on validation set is SVM.\n",
      "Classifier with higest accuracy on validation set is SVM.\n",
      "Accuracy: 0.85 (0.03)\n"
     ]
    }
   ],
   "source": [
    "##---  Model selection demo based on from support vector machine, random forest, k-nearest neighbors, using nested k-fold cross-validation ---##\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "##---  Prepare the Outer Loop cross-validation procedure ---##\n",
    "OutKF = KFold(n_splits=5,shuffle=True,random_state=920)\n",
    "##---   If we want to make sure that the proportion of samples in the training and test set is the same as in the original dataset, we should adopt 'StratifiedKFold' ---##\n",
    "# OutKF = StratifiedKFold(n_outer,shuffle=True, random_state=920+i)\n",
    "\n",
    "scores = []\n",
    "for train_index,test_index in OutKF.split(x,y):\n",
    "    ##---  Seperate traing set and test set ---##\n",
    "    x_train, x_test = x.iloc[train_index][:], x.iloc[test_index][:]\n",
    "    y_train, y_test = y.iloc[train_index][:], y.iloc[test_index][:]\n",
    "\n",
    "    ##---  Prepare the Inner Loop cross-validation procedure ---##\n",
    "    valscores0 = []\n",
    "    valscores1 = []\n",
    "    valscores2 = []\n",
    "    InnKF = KFold(n_splits=5,shuffle=True,random_state=920)\n",
    "    for subtrain_index,valid_index in InnKF.split(x_train,y_train):\n",
    "        #---  Seperate subtraing set and validation set ---#\n",
    "        x_subtrain, x_valid = x_train.iloc[subtrain_index][:], x_train.iloc[valid_index][:]\n",
    "        y_subtrain, y_valid = y_train.iloc[subtrain_index][:], y_train.iloc[valid_index][:]\n",
    "        #---  creat and train the model ---#\n",
    "        clf0 = svm.SVC(kernel = 'rbf', gamma='auto', probability=True,random_state=920).fit(x_subtrain,y_subtrain)\n",
    "        clf1 = ensemble.RandomForestClassifier(random_state=920).fit(x_subtrain,y_subtrain)\n",
    "        clf2 = neighbors.KNeighborsClassifier().fit(x_subtrain,y_subtrain)\n",
    "        #---  Make the prediction ---#\n",
    "        y_valpred0 = clf0.predict(x_valid)\n",
    "        y_valpred1 = clf1.predict(x_valid)\n",
    "        y_valpred2 = clf2.predict(x_valid)\n",
    "        #---  Evaluate model on the specific validation set ---#\n",
    "        valscore0 = metrics.accuracy_score(y_valid,y_valpred0)\n",
    "        valscores0.append(valscore0) \n",
    "        valscore1 = metrics.accuracy_score(y_valid,y_valpred1)\n",
    "        valscores1.append(valscore1)\n",
    "        valscore2 = metrics.accuracy_score(y_valid,y_valpred2)\n",
    "        valscores2.append(valscore2)\n",
    "    valscore = [mean(valscore0),mean(valscore1),mean(valscore2)]\n",
    "    max_index = valscore.index(max(valscore))\n",
    "        \n",
    "    ##---  Seclet the best model and evaluate model on the specific test set ---##\n",
    "    # clf0 = svm.SVC(kernel = 'rbf', gamma='auto', probability=True).fit(x_train,y_train)\n",
    "    # clf1 = ensemble.RandomForestClassifier().fit(x_train,y_train)\n",
    "    # clf2 = neighbors.KNeighborsClassifier().fit(x_train,y_train)\n",
    "    if max_index == 0:\n",
    "        clf = svm.SVC(kernel = 'rbf', gamma='auto', probability=True).fit(x_train,y_train)\n",
    "        print('Classifier with higest accuracy on validation set is SVM.')\n",
    "    else:\n",
    "        if max_index == 1:\n",
    "            clf = ensemble.RandomForestClassifier().fit(x_train,y_train)\n",
    "            print('Classifier with higest accuracy on validation set is RandomForest.')\n",
    "        else:\n",
    "            clf = neighbors.KNeighborsClassifier().fit(x_train,y_train)\n",
    "            print('Classifier with higest accuracy on validation set is KNN.')\n",
    "   \n",
    "    ##---  Evaluate model on the specific test set ---##\n",
    "    y_pred = clf.predict(x_test)\n",
    "    score = metrics.accuracy_score(y_test, y_pred)\n",
    "    scores.append(score) \n",
    "\n",
    "##---  Report performance on test set---##\n",
    "print('Accuracy in each split:',scores)\n",
    "print('Mean and  standard deviation of accuracy: %.2f (%.2f)' % (mean(scores),std(scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Select different hyperparameters of models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higest accuracy and the corresponding parameter is : 0.72 (11).\n",
      "Higest accuracy and the corresponding parameter is : 0.74 (1).\n",
      "Higest accuracy and the corresponding parameter is : 0.70 (11).\n",
      "Higest accuracy and the corresponding parameter is : 0.72 (11).\n",
      "Higest accuracy and the corresponding parameter is : 0.71 (11).\n",
      "Accuracy in each split: [0.8470588235294118, 0.7411764705882353, 0.788235294117647, 0.8214285714285714, 0.7142857142857143]\n",
      "Mean and  standard deviation of accuracy: 0.78 (0.05)\n"
     ]
    }
   ],
   "source": [
    "##---  Model selection demo based on different number of neighbors for KNN, using nested k-fold cross-validation ---##\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "n_outer = 5 # number of splits for outer loop\n",
    "n_inner = 5 # number of splits for inner loop\n",
    "range_n = [1, 10**2] # list, float, range of parameter n\n",
    "step_n =10 # step of candidate parameters\n",
    "\n",
    "parameters = {'n_neighbors':range(range_n[0],range_n[1]+2,step_n)}\n",
    "\n",
    "##---  Prepare the Outer Loop cross-validation procedure ---##\n",
    "OutKF = KFold(n_splits=5,shuffle=True,random_state=920)\n",
    "##---   If we want to make sure that the proportion of samples in the training and test set is the same as in the original dataset, we should adopt 'StratifiedKFold' ---##\n",
    "# OutKF = StratifiedKFold(n_outer,shuffle=True, random_state=920+i)\n",
    "\n",
    "scores = []\n",
    "for train_index,test_index in OutKF.split(x,y):\n",
    "    ##---  Seperate traing set and test set ---##\n",
    "    x_train, x_test = x.iloc[train_index][:], x.iloc[test_index][:]\n",
    "    y_train, y_test = y.iloc[train_index][:], y.iloc[test_index][:]\n",
    "\n",
    "    ##---  Implement the Inner Loop cross-validation and parameter exploring procedure using grid search ---##\n",
    "    estimator = neighbors.KNeighborsClassifier()\n",
    "    clf = model_selection.GridSearchCV(estimator,parameters,cv=n_inner,verbose=0,scoring='accuracy').fit(x_train, y_train)\n",
    "    \n",
    "#     print('Higest accuracy and the corresponding parameter is : %.2f (%d).' %(clf.best_score_,clf.best_params_['n_neighbors']))\n",
    "\n",
    "    ##---  Evaluate model on the specific test set ---##\n",
    "    y_pred = clf.predict(x_test)\n",
    "    score = metrics.accuracy_score(y_test, y_pred)\n",
    "    scores.append(score) \n",
    "\n",
    "##---  Report performance on test set---##\n",
    "print('Accuracy in each split:',scores)\n",
    "print('Mean and  standard deviation of accuracy: %.2f (%.2f)' % (mean(scores),std(scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analytical Measures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Akaike Information Criterion (AIC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- - - - - - - - - - \n",
      "In 1th iteration:\n",
      "- - - - - - - - - - \n",
      "Number of parameters for clf0: 13\n",
      "Number of parameters for clf1: 9\n",
      "Number of parameters for clf2: 3\n",
      "Mse for clf0: 0.158660\n",
      "Mse for clf1: 0.182019\n",
      "Mse for clf2: 0.208360\n",
      "AIC: [-329380.3199936178, -304813.523050753, -280641.97077876364]\n",
      "The best model is model 0.\n",
      "- - - - - - - - - - \n",
      "In 2th iteration:\n",
      "- - - - - - - - - - \n",
      "Number of parameters for clf0: 13\n",
      "Number of parameters for clf1: 8\n",
      "Number of parameters for clf2: 5\n",
      "Mse for clf0: 0.152828\n",
      "Mse for clf1: 0.180776\n",
      "Mse for clf2: 0.208004\n",
      "AIC: [-336081.98603828734, -306041.23911747476, -280944.15397766704]\n",
      "The best model is model 0.\n",
      "- - - - - - - - - - \n",
      "In 3th iteration:\n",
      "- - - - - - - - - - \n",
      "Number of parameters for clf0: 12\n",
      "Number of parameters for clf1: 8\n",
      "Number of parameters for clf2: 4\n",
      "Mse for clf0: 0.164440\n",
      "Mse for clf1: 0.191215\n",
      "Mse for clf2: 0.216330\n",
      "AIC: [-322980.6594710439, -295996.28212320723, -273923.59108677466]\n",
      "The best model is model 0.\n",
      "- - - - - - - - - - - - - - - - - - - - \n",
      "Final model：\n",
      "Accuracy: 0.79 (0.01) [0.8013245033112583, 0.7801418439716312, 0.7876712328767124]\n",
      "- - - - - - - - - - - - - - - - - - - - \n"
     ]
    }
   ],
   "source": [
    "##---  Model selection demo based on AIC for LASSO nested in the model evaluation method of bootstrap ---##\n",
    "\n",
    "from mlxtend.evaluate import bootstrap_point632_score,BootstrapOutOfBag\n",
    "\n",
    "##---  Compute number of paramters for the linear model ---##\n",
    "def compute_num_parameters(coef):\n",
    "    num_para = np.sum((np.abs(coef) > np.finfo(coef.dtype).eps)!=0)\n",
    "    return num_para\n",
    "\n",
    "##---  Compute AIC for SVM with linear kernel ---##\n",
    "def compute_aic(n, mse, num_params):\n",
    "    AIC = n* n * log(mse) + 2 * num_params\n",
    "    return AIC\n",
    "\n",
    "##---  Prepare the bootstrap procedure ---##\n",
    "n_outer = 3 # number of splits/repeats for outer loop (Model evaluation)\n",
    "oob = BootstrapOutOfBag(n_splits=n_outer,random_seed=920)\n",
    "\n",
    "scores = []\n",
    "i = 0\n",
    "for train_index, test_index in oob.split(x,y):\n",
    "    i+=1\n",
    "    print('- '*10)\n",
    "    print('In %dth iteration:'%(i))\n",
    "    print('- '*10)\n",
    "    ##---  Seperate traing set and test set ---##\n",
    "    x_train, x_test = x.iloc[train_index][:], x.iloc[test_index][:]\n",
    "    y_train, y_test = y.iloc[train_index][:],y.iloc[test_index][:]\n",
    "    ##---  creat and train the model with different parameters---##\n",
    "    clf0 = linear_model.Lasso(alpha=0.1).fit(x_train,y_train)\n",
    "    clf1 = linear_model.Lasso(alpha=0.2).fit(x_train,y_train)\n",
    "    clf2 = linear_model.Lasso(alpha=0.3).fit(x_train,y_train)\n",
    "    ##---  Make the prediction ---##\n",
    "    y_pred0 = clf0.predict(x_train)\n",
    "    y_pred1 = clf1.predict(x_train)\n",
    "    y_pred2 = clf2.predict(x_train)\n",
    "    \n",
    "    ##---  Compute AIC on the specific training set ---##\n",
    "    # number of parameters\n",
    "    num_params0 = compute_num_parameters(clf0.coef_) + 1\n",
    "    print('Number of parameters for clf0: %d' % (num_params0))\n",
    "    num_params1 = compute_num_parameters(clf1.coef_) + 1\n",
    "    print('Number of parameters for clf1: %d' % (num_params1))\n",
    "    num_params2 = compute_num_parameters(clf2.coef_) + 1\n",
    "    print('Number of parameters for clf2: %d' % (num_params2))\n",
    "    # maximum likelihood\n",
    "    mse0 = metrics.mean_squared_error(y_train, y_pred0)\n",
    "    print('Mse for clf0: %f' % mse0)\n",
    "    mse1 = metrics.mean_squared_error(y_train, y_pred1)\n",
    "    print('Mse for clf1: %f' % mse1)\n",
    "    mse2 = metrics.mean_squared_error(y_train, y_pred2)\n",
    "    print('Mse for clf2: %f' % mse2)\n",
    "    # AIC\n",
    "    AIC = [compute_aic(len(y_train), mse0, num_params0), compute_aic(len(y_train), mse1, num_params1), \n",
    "            compute_aic(len(y_train), mse2, num_params2)]\n",
    "    print('AIC:',AIC)\n",
    "    \n",
    "    ##---  Seclet the best model and evaluate model on the specific test set ---##\n",
    "    min_index = AIC.index(min(AIC))\n",
    "    print('The best model is model %d.' % min_index)\n",
    "    if min_index == 0:\n",
    "        y_pred = int64(clf0.predict(x_test)>0.5)\n",
    "    else:\n",
    "        if min_index == 1:\n",
    "            y_pred = int64(clf1.predict(x_test)>0.5)\n",
    "        else:\n",
    "            y_pred = int64(clf2.predict(x_test)>0.5)\n",
    "   \n",
    "    ##---  Evaluate model on the specific test set ---##\n",
    "    score = metrics.accuracy_score(y_test, y_pred)\n",
    "    scores.append(score)\n",
    "    \n",
    "\n",
    "# ##---  Report performance ---##\n",
    "print('- '*20)\n",
    "print('Final model：')\n",
    "print('Accuracy: %.2f (%.2f)' % (mean(scores), std(scores)), scores)\n",
    "print('- '*20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Bayesian Information Criterion (BIC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- - - - - - - - - - \n",
      "In 1th iteration:\n",
      "- - - - - - - - - - \n",
      "Number of parameters for clf0: 31\n",
      "Number of parameters for clf1: 13\n",
      "Number of parameters for clf2: 9\n",
      "Mse for clf0: 0.120383\n",
      "Mse for clf1: 0.158660\n",
      "Mse for clf2: 0.182019\n",
      "BIC: [-378619.3264831722, -329327.7041552902, -304777.09670114156]\n",
      "The best model is model 0.\n",
      "- - - - - - - - - - \n",
      "In 2th iteration:\n",
      "- - - - - - - - - - \n",
      "Number of parameters for clf0: 31\n",
      "Number of parameters for clf1: 13\n",
      "Number of parameters for clf2: 8\n",
      "Mse for clf0: 0.118425\n",
      "Mse for clf1: 0.152828\n",
      "Mse for clf2: 0.180776\n",
      "BIC: [-381553.040246516, -336029.3701999597, -306008.8601400424]\n",
      "The best model is model 0.\n",
      "- - - - - - - - - - \n",
      "In 3th iteration:\n",
      "- - - - - - - - - - \n",
      "Number of parameters for clf0: 33\n",
      "Number of parameters for clf1: 12\n",
      "Number of parameters for clf2: 8\n",
      "Mse for clf0: 0.119737\n",
      "Mse for clf1: 0.164440\n",
      "Mse for clf2: 0.191215\n",
      "BIC: [-379569.4989552182, -322932.09100489534, -295963.90314577485]\n",
      "The best model is model 0.\n",
      "- - - - - - - - - - - - - - - - - - - - \n",
      "Final model：\n",
      "Accuracy: 0.83 (0.01) [0.8145695364238411, 0.8368794326241135, 0.8356164383561644]\n",
      "- - - - - - - - - - - - - - - - - - - - \n"
     ]
    }
   ],
   "source": [
    "##---  Model selection demo based on AIC for LASSO nested in the model evaluation method of bootstrap ---##\n",
    "\n",
    "from mlxtend.evaluate import bootstrap_point632_score,BootstrapOutOfBag\n",
    "\n",
    "##---  Compute number of paramters for the linear model ---##\n",
    "def compute_num_parameters(coef):\n",
    "    num_para = np.sum((np.abs(coef) > np.finfo(coef.dtype).eps)!=0)\n",
    "    return num_para\n",
    "\n",
    "##---  Compute BIC ---##\n",
    "def compute_bic(n, mse, num_params):\n",
    "    BIC = n * n * log(mse) + num_params * log(n)\n",
    "    return BIC\n",
    "\n",
    "##---  Prepare the bootstrap procedure ---##\n",
    "n_outer = 3 # number of splits/repeats for outer loop (Model evaluation)\n",
    "oob = BootstrapOutOfBag(n_splits=n_outer,random_seed=920)\n",
    "\n",
    "scores = []\n",
    "i = 0\n",
    "for train_index, test_index in oob.split(x,y):\n",
    "    i+=1\n",
    "    print('- '*10)\n",
    "    print('In %dth iteration:'%(i))\n",
    "    print('- '*10)\n",
    "    ##---  Seperate traing set and test set ---##\n",
    "    x_train, x_test = x.iloc[train_index][:], x.iloc[test_index][:]\n",
    "    y_train, y_test = y.iloc[train_index][:],y.iloc[test_index][:]\n",
    "    ##---  creat and train the model with different parameters---##\n",
    "    clf0 = linear_model.Lasso(alpha=0.01).fit(x_train,y_train)\n",
    "    clf1 = linear_model.Lasso(alpha=0.1).fit(x_train,y_train)\n",
    "    clf2 = linear_model.Lasso(alpha=0.2).fit(x_train,y_train)\n",
    "    ##---  Make the prediction ---##\n",
    "    y_pred0 = clf0.predict(x_train)\n",
    "    y_pred1 = clf1.predict(x_train)\n",
    "    y_pred2 = clf2.predict(x_train)\n",
    "    \n",
    "    ##---  Compute AIC on the specific training set ---##\n",
    "    # number of parameters\n",
    "    num_params0 = compute_num_parameters(clf0.coef_) + 1\n",
    "    print('Number of parameters for clf0: %d' % (num_params0))\n",
    "    num_params1 = compute_num_parameters(clf1.coef_) + 1\n",
    "    print('Number of parameters for clf1: %d' % (num_params1))\n",
    "    num_params2 = compute_num_parameters(clf2.coef_) + 1\n",
    "    print('Number of parameters for clf2: %d' % (num_params2))\n",
    "    # maximum likelihood\n",
    "    mse0 = metrics.mean_squared_error(y_train, y_pred0)\n",
    "    print('Mse for clf0: %f' % mse0)\n",
    "    mse1 = metrics.mean_squared_error(y_train, y_pred1)\n",
    "    print('Mse for clf1: %f' % mse1)\n",
    "    mse2 = metrics.mean_squared_error(y_train, y_pred2)\n",
    "    print('Mse for clf2: %f' % mse2)\n",
    "    # BIC\n",
    "    BIC = [compute_bic(len(y_train), mse0, num_params0), compute_bic(len(y_train), mse1, num_params1), \n",
    "            compute_bic(len(y_train), mse2, num_params2)]\n",
    "    print('BIC:',BIC)\n",
    "    \n",
    "    ##---  Seclet the best model and evaluate model on the specific test set ---##\n",
    "    min_index = BIC.index(min(BIC))\n",
    "    print('The best model is model %d.' % min_index)\n",
    "    if min_index == 0:\n",
    "        y_pred = int64(clf0.predict(x_test)>0.5)\n",
    "    else:\n",
    "        if min_index == 1:\n",
    "            y_pred = int64(clf1.predict(x_test)>0.5)\n",
    "        else:\n",
    "            y_pred = int64(clf2.predict(x_test)>0.5)\n",
    "   \n",
    "    ##---  Evaluate model on the specific test set ---##\n",
    "    score = metrics.accuracy_score(y_test, y_pred)\n",
    "    scores.append(score)\n",
    "    \n",
    "\n",
    "# ##---  Report performance ---##\n",
    "print('- '*20)\n",
    "print('Final model：')\n",
    "print('Accuracy: %.2f (%.2f)' % (mean(scores), std(scores)), scores)\n",
    "print('- '*20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Minimum  Description  Length  (MDL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##---  Model selection demo based on AIC for SVM nested in the model evaluation method of bootstrap ---##\n",
    "\n",
    "##---  Compute AIC for SVM with linear kernel ---##\n",
    "def compute_aic(n, mse, num_params):\n",
    "    AIC = n * log(mse) + 2 * num_params\n",
    "    return AIC\n",
    "from mlxtend.evaluate import bootstrap_point632_score,BootstrapOutOfBag\n",
    "\n",
    "n_outer = 2 # number of splits/repeats for outer loop (Model evaluation)\n",
    "rangeC = [10**-2,5] # list, float, range of parameter C,eg.[10**-2, 10**2]\n",
    "rangeGamma = [10**-2,1] # list, float, range of parameter gamma,eg.[10**-6, 10**1]\n",
    "num_C = 3 # number of cadidate values of parameter C for SVM, to tune the interval of parameter\n",
    "num_gamma = 3 # number of cadidate values of parameter gamma for SVM, to tune the interval of parameter\n",
    "parameters = {'C':linspace(rangeC[0],rangeC[1],num_C),'gamma':linspace(rangeGamma[0],rangeGamma[1],num_gamma)}\n",
    "\n",
    "\n",
    "##---  Prepare the bootstrap procedure ---##\n",
    "oob = BootstrapOutOfBag(n_splits=n_outer,random_seed=920)\n",
    "\n",
    "scores = []\n",
    "for train_index, test_index in oob.split(x,y):\n",
    "    print('-'*20)\n",
    "    print('In %dth iteration:'%(oob.get_n_splits()))\n",
    "    ##---  Seperate traing set and test set ---##\n",
    "    x_train, x_test = x.iloc[train_index][:], x.iloc[test_index][:]\n",
    "    y_train, y_test = y.iloc[train_index][:],y.iloc[test_index][:]\n",
    "    ##---  creat and train the model with different parameters---##\n",
    "    clf0 = svm.SVC(kernel='linear',C=parameters['C'][0],gamma=parameters['gamma'][0]).fit(x_train,y_train)\n",
    "    clf1 = svm.SVC(kernel='linear',C=parameters['C'][1],gamma=parameters['gamma'][1]).fit(x_train,y_train)\n",
    "    clf2 = svm.SVC(kernel='linear',C=parameters['C'][2],gamma=parameters['gamma'][2]).fit(x_train,y_train)\n",
    "#     clf0 = linear_model.RidgeClassifier(alpha=0).fit(x_train,y_train)\n",
    "#     clf1 = linear_model.RidgeClassifier(alpha=1).fit(x_train,y_train)\n",
    "#     clf2 = linear_model.RidgeClassifier(alpha=300).fit(x_train,y_train)\n",
    "#     clf0 = linear_model.Lasso(alpha=0).fit(x_train,y_train)\n",
    "#     clf1 = linear_model.Lasso(alpha=0.1).fit(x_train,y_train)\n",
    "#     clf2 = linear_model.Lasso(alpha=1).fit(x_train,y_train)\n",
    "    ##---  Make the prediction ---##\n",
    "    y_pred0 = clf0.predict(x_train)\n",
    "    y_pred1 = clf1.predict(x_train)\n",
    "    y_pred2 = clf2.predict(x_train)\n",
    "    print(clf0.coef_[0])\n",
    "    print(clf1.coef_[0])\n",
    "    print(clf2.coef_[0])\n",
    "    \n",
    "    ##---  Compute AIC on the specific training set ---##\n",
    "    # number of parameters\n",
    "    num_params0 = len(clf0.coef_[0]) + 1\n",
    "    print('Number of parameters for clf0: %d' % (num_params0))\n",
    "    num_params1 = len(clf1.coef_[0]) + 1\n",
    "    print('Number of parameters for clf1: %d' % (num_params1))\n",
    "    num_params2 = len(clf2.coef_[0]) + 1\n",
    "    print('Number of parameters for clf2: %d' % (num_params2))\n",
    "\n",
    "    \n",
    "#     ##---  Compute AIC on the specific training set ---##\n",
    "#     # number of parameters\n",
    "#     num_params0 = len(clf0.coef_) + 1\n",
    "#     print('Number of parameters for clf0: %d' % (num_params0))\n",
    "#     num_params1 = len(clf1.coef_) + 1\n",
    "#     print('Number of parameters for clf1: %d' % (num_params1))\n",
    "#     num_params2 = len(clf2.coef_) + 1\n",
    "#     print('Number of parameters for clf2: %d' % (num_params2))\n",
    "    # maximum likelihood\n",
    "    mse0 = metrics.mean_squared_error(y_train, y_pred0)\n",
    "    print('Mse for clf0: %f' %mse0)\n",
    "    mse1 = metrics.mean_squared_error(y_train, y_pred1)\n",
    "    print('Mse for clf1: %f' %mse1)\n",
    "    mse2 = metrics.mean_squared_error(y_train, y_pred2)\n",
    "    print('Mse for clf2: %f' %mse2)\n",
    "    \n",
    "    \n",
    "    \n",
    "    max_index = valscore.index(max(valscore))\n",
    "    ##---  Evaluate model on the specific test set ---##\n",
    "#     y_pred = clf1.predict(x_test)\n",
    "    y_pred = int64(clf0.predict(x_test))\n",
    "    score = metrics.accuracy_score(y_test, y_pred)\n",
    "    scores.append(score)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# ##---  Report performance ---##\n",
    "print('Accuracy: %.2f (%.2f)' % (mean(scores), std(scores)))\n",
    "print(scores)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
